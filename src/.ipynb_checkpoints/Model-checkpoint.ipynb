{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'DataLoader'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-548ca873942b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mDataLoader\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mFilePaths\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'DataLoader'"
     ]
    }
   ],
   "source": [
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "import codecs\n",
    "import sys\n",
    "\n",
    "import tensorflow.compat.v1 as tf\n",
    "\n",
    "\n",
    "\n",
    "from DataLoader import FilePaths\n",
    "\n",
    "\n",
    "class DecoderType:\n",
    "    BestPath = 0\n",
    "    WordBeamSearch = 1\n",
    "    BeamSearch = 2\n",
    "\n",
    "\n",
    "class Model:\n",
    "    # Model Constants\n",
    "    batchSize = 10 # 50\n",
    "    imgSize = (800, 64) \n",
    "    maxTextLen = 100 # maximum text length can be reccognized\n",
    "\n",
    "    def __init__(self, charList, decoderType=DecoderType.BestPath, mustRestore=False):\n",
    "        tf.disable_v2_behavior()\n",
    "        self.charList = charList\n",
    "        self.decoderType = decoderType\n",
    "        self.mustRestore = mustRestore\n",
    "        self.snapID = 0\n",
    "\n",
    "\n",
    "        # input image batch\n",
    "        self.inputImgs = tf.compat.v1.placeholder(tf.float32, shape=(None, Model.imgSize[0], Model.imgSize[1]))\n",
    "\n",
    "        # setup CNN, RNN and CTC\n",
    "        self.setupCNN()\n",
    "        self.setupRNN()\n",
    "        self.setupCTC()\n",
    "\n",
    "        # setup optimizer to train NN\n",
    "\n",
    "        self.batchesTrained = 0\n",
    "        self.learningRate = tf.compat.v1.placeholder(tf.float32, shape=[])\n",
    "        self.optimizer = tf.compat.v1.train.RMSPropOptimizer(self.learningRate).minimize(self.loss)\n",
    "\n",
    "        # Initialize TensorFlow\n",
    "        (self.sess, self.saver) = self.setupTF()\n",
    "\n",
    "        self.training_loss_summary = tf.compat.v1.summary.scalar('loss', self.loss)\n",
    "        self.writer = tf.compat.v1.summary.FileWriter(\n",
    "           './logs', self.sess.graph)  # Tensorboard: Create writer\n",
    "        self.merge = tf.compat.v1.summary.merge([self.training_loss_summary])  # Tensorboard: Merge\n",
    "\n",
    "    def setupCNN(self):\n",
    "        \"\"\" Create CNN layers and return output of these layers \"\"\"\n",
    "\n",
    "        cnnIn4d = tf.expand_dims(input=self.inputImgs, axis=3)\n",
    "\n",
    "        # First Layer: Conv (5x5) + Pool (2x2) - Output size: 400 x 32 x 64\n",
    "        with tf.compat.v1.name_scope('Conv_Pool_1'):\n",
    "            kernel = tf.Variable(\n",
    "                tf.random.truncated_normal([5, 5, 1, 64], stddev=0.1))\n",
    "            conv = tf.nn.conv2d(\n",
    "                input=cnnIn4d, filters=kernel, padding='SAME', strides=(1, 1, 1, 1))\n",
    "            learelu = tf.nn.leaky_relu(conv, alpha=0.01)\n",
    "            pool = tf.nn.max_pool2d(input=learelu, ksize=(1, 2, 2, 1), strides=(1, 2, 2, 1), padding='VALID')\n",
    "\n",
    "        # Second Layer: Conv (5x5) + Pool (1x2) - Output size: 400 x 16 x 128\n",
    "        with tf.compat.v1.name_scope('Conv_Pool_2'):\n",
    "            kernel = tf.Variable(tf.random.truncated_normal(\n",
    "                [5, 5, 64, 128], stddev=0.1))\n",
    "            conv = tf.nn.conv2d(\n",
    "                input=pool, filters=kernel, padding='SAME', strides=(1, 1, 1, 1))\n",
    "            learelu = tf.nn.leaky_relu(conv, alpha=0.01)\n",
    "            pool = tf.nn.max_pool2d(input=learelu, ksize=(1, 1, 2, 1), strides=(1, 1, 2, 1), padding='VALID')\n",
    "\n",
    "        # Third Layer: Conv (3x3) + Pool (2x2) + Simple Batch Norm - Output size: 200 x 8 x 128\n",
    "        with tf.compat.v1.name_scope('Conv_Pool_BN_3'):\n",
    "            kernel = tf.Variable(tf.random.truncated_normal(\n",
    "                [3, 3, 128, 128], stddev=0.1))\n",
    "            conv = tf.nn.conv2d(\n",
    "                input=pool, filters=kernel, padding='SAME', strides=(1, 1, 1, 1))\n",
    "            mean, variance = tf.nn.moments(x=conv, axes=[0])\n",
    "            batch_norm = tf.nn.batch_normalization(\n",
    "                conv, mean, variance, offset=None, scale=None, variance_epsilon=0.001)\n",
    "            learelu = tf.nn.leaky_relu(batch_norm, alpha=0.01)\n",
    "            pool = tf.nn.max_pool2d(input=learelu, ksize=(1, 2, 2, 1), strides=(1, 2, 2, 1), padding='VALID')\n",
    "\n",
    "        # Fourth Layer: Conv (3x3) - Output size: 200 x 8 x 256\n",
    "        with tf.compat.v1.name_scope('Conv_4'):\n",
    "            kernel = tf.Variable(tf.random.truncated_normal(\n",
    "                [3, 3, 128, 256], stddev=0.1))\n",
    "            conv = tf.nn.conv2d(\n",
    "                input=pool, filters=kernel, padding='SAME', strides=(1, 1, 1, 1))\n",
    "            learelu = tf.nn.leaky_relu(conv, alpha=0.01)\n",
    "\n",
    "        # Fifth Layer: Conv (3x3) + Pool(2x2) - Output size: 100 x 4 x 256\n",
    "        with tf.compat.v1.name_scope('Conv_Pool_5'):\n",
    "            kernel = tf.Variable(tf.random.truncated_normal(\n",
    "                [3, 3, 256, 256], stddev=0.1))\n",
    "            conv = tf.nn.conv2d(\n",
    "                input=learelu, filters=kernel, padding='SAME', strides=(1, 1, 1, 1))\n",
    "            learelu = tf.nn.leaky_relu(conv, alpha=0.01)\n",
    "            pool = tf.nn.max_pool2d(input=learelu, ksize=(1, 2, 2, 1), strides=(1, 2, 2, 1), padding='VALID')\n",
    "\n",
    "        # Sixth Layer: Conv (3x3) + Pool(1x2) + Simple Batch Norm - Output size: 100 x 2 x 512\n",
    "        with tf.compat.v1.name_scope('Conv_Pool_BN_6'):\n",
    "            kernel = tf.Variable(tf.random.truncated_normal(\n",
    "                [3, 3, 256, 512], stddev=0.1))\n",
    "            conv = tf.nn.conv2d(\n",
    "                input=pool, filters=kernel, padding='SAME', strides=(1, 1, 1, 1))\n",
    "            mean, variance = tf.nn.moments(x=conv, axes=[0])\n",
    "            batch_norm = tf.nn.batch_normalization(\n",
    "                conv, mean, variance, offset=None, scale=None, variance_epsilon=0.001)\n",
    "            learelu = tf.nn.leaky_relu(batch_norm, alpha=0.01)\n",
    "            pool = tf.nn.max_pool2d(input=learelu, ksize=(1, 1, 2, 1), strides=(1, 1, 2, 1), padding='VALID')\n",
    "\n",
    "\n",
    "        # Seventh Layer: Conv (3x3) + Pool (1x2) - Output size: 100 x 1 x 512\n",
    "        with tf.compat.v1.name_scope('Conv_Pool_7'):\n",
    "            kernel = tf.Variable(tf.random.truncated_normal(\n",
    "                [3, 3, 512, 512], stddev=0.1))\n",
    "            conv = tf.nn.conv2d(\n",
    "                input=pool, filters=kernel, padding='SAME', strides=(1, 1, 1, 1))\n",
    "            learelu = tf.nn.leaky_relu(conv, alpha=0.01)\n",
    "            pool = tf.nn.max_pool2d(input=learelu, ksize=(1, 1, 2, 1), strides=(1, 1, 2, 1), padding='VALID')\n",
    "\n",
    "            self.cnnOut4d = pool\n",
    "\n",
    "    def setupRNN(self):\n",
    "        \"\"\" Create RNN layers and return output of these layers \"\"\"\n",
    "        # Collapse layer to remove dimension 100 x 1 x 512 --> 100 x 512 on axis=2\n",
    "        rnnIn3d = tf.squeeze(self.cnnOut4d, axis=[2])\n",
    "\n",
    "        # 2 layers of LSTM cell used to build RNN\n",
    "        numHidden = 512\n",
    "        cells = [tf.compat.v1.nn.rnn_cell.LSTMCell(\n",
    "            num_units=numHidden, state_is_tuple=True, name='basic_lstm_cell') for _ in range(2)]\n",
    "        stacked = tf.compat.v1.nn.rnn_cell.MultiRNNCell(cells, state_is_tuple=True)\n",
    "        # Bi-directional RNN\n",
    "        # BxTxF -> BxTx2H\n",
    "        ((forward, backward), _) = tf.compat.v1.nn.bidirectional_dynamic_rnn(\n",
    "            cell_fw=stacked, cell_bw=stacked, inputs=rnnIn3d, dtype=rnnIn3d.dtype)\n",
    "\n",
    "        # BxTxH + BxTxH -> BxTx2H -> BxTx1X2H\n",
    "        concat = tf.expand_dims(tf.concat([forward, backward], 2), 2)\n",
    "\n",
    "        # Project output to chars (including blank): BxTx1x2H -> BxTx1xC -> BxTxC\n",
    "        kernel = tf.Variable(tf.random.truncated_normal(\n",
    "            [1, 1, numHidden * 2, len(self.charList) + 1], stddev=0.1))\n",
    "        self.rnnOut3d = tf.squeeze(tf.nn.atrous_conv2d(value=concat, filters=kernel, rate=1, padding='SAME'), axis=[2])\n",
    "\n",
    "    def setupCTC(self):\n",
    "        \"\"\" Create CTC loss and decoder and return them \"\"\"\n",
    "        # BxTxC -> TxBxC\n",
    "        self.ctcIn3dTBC = tf.transpose(a=self.rnnOut3d, perm=[1, 0, 2])\n",
    "\n",
    "        # Ground truth text as sparse tensor\n",
    "        with tf.compat.v1.name_scope('CTC_Loss'):\n",
    "            self.gtTexts = tf.SparseTensor(tf.compat.v1.placeholder(tf.int64, shape=[\n",
    "                                           None, 2]), tf.compat.v1.placeholder(tf.int32, [None]), tf.compat.v1.placeholder(tf.int64, [2]))\n",
    "            # Calculate loss for batch\n",
    "            self.seqLen = tf.compat.v1.placeholder(tf.int32, [None])\n",
    "            self.loss = tf.reduce_mean(input_tensor=tf.compat.v1.nn.ctc_loss(labels=self.gtTexts, inputs=self.ctcIn3dTBC, sequence_length=self.seqLen,\n",
    "                               ctc_merge_repeated=True, ignore_longer_outputs_than_inputs=True))\n",
    "        with tf.compat.v1.name_scope('CTC_Decoder'):\n",
    "            # Decoder: Best path decoding or Word beam search decoding\n",
    "            if self.decoderType == DecoderType.BestPath:\n",
    "                self.decoder = tf.nn.ctc_greedy_decoder(\n",
    "                    inputs=self.ctcIn3dTBC, sequence_length=self.seqLen)\n",
    "            elif self.decoderType == DecoderType.BeamSearch:\n",
    "                self.decoder = tf.compat.v1.nn.ctc_beam_search_decoder(inputs=self.ctcIn3dTBC, sequence_length=self.seqLen, beam_width=50, merge_repeated=True)\n",
    "            elif self.decoderType == DecoderType.WordBeamSearch:\n",
    "                # Import compiled word beam search operation (see https://github.com/githubharald/CTCWordBeamSearch)\n",
    "                word_beam_search_module = tf.load_op_library(\n",
    "                    './TFWordBeamSearch.so')\n",
    "\n",
    "                # Prepare: dictionary, characters in dataset, characters forming words\n",
    "                chars = codecs.open(FilePaths.wordCharList.txt, 'r').read()\n",
    "                wordChars = codecs.open(\n",
    "                    FilePaths.fnWordCharList, 'r').read()\n",
    "                corpus = codecs.open(FilePaths.corpus.txt, 'r').read()\n",
    "\n",
    "                # # Decoder using the \"NGramsForecastAndSample\": restrict number of (possible) next words to at most 20 words: O(W) mode of word beam search\n",
    "                # decoder = word_beam_search_module.word_beam_search(tf.nn.softmax(ctcIn3dTBC, dim=2), 25, 'NGramsForecastAndSample', 0.0, corpus.encode('utf8'), chars.encode('utf8'), wordChars.encode('utf8'))\n",
    "\n",
    "                # Decoder using the \"Words\": only use dictionary, no scoring: O(1) mode of word beam search\n",
    "                self.decoder = word_beam_search_module.word_beam_search(tf.nn.softmax(\n",
    "                    self.ctcIn3dTBC, axis=2), 25, 'Words', 0.0, corpus.encode('utf8'), chars.encode('utf8'), wordChars.encode('utf8'))\n",
    "\n",
    "        # Return a CTC operation to compute the loss and CTC operation to decode the RNN output\n",
    "        return self.loss, self.decoder\n",
    "\n",
    "    def setupTF(self):\n",
    "        \"\"\" Initialize TensorFlow \"\"\"\n",
    "        print('Python: ' + sys.version)\n",
    "        print('Tensorflow: ' + tf.__version__)\n",
    "        sess = tf.compat.v1.Session()  # Tensorflow session\n",
    "        saver = tf.compat.v1.train.Saver(max_to_keep=3)  # Saver saves model to file\n",
    "        modelDir = '../model/'\n",
    "        latestSnapshot = tf.train.latest_checkpoint(modelDir)  # Is there a saved model?\n",
    "        # If model must be restored (for inference), there must be a snapshot\n",
    "        if self.mustRestore and not latestSnapshot:\n",
    "            raise Exception('No saved model found in: ' + modelDir)\n",
    "        # Load saved model if available\n",
    "        if latestSnapshot:\n",
    "            print('Init with stored values from ' + latestSnapshot)\n",
    "            saver.restore(sess, latestSnapshot)\n",
    "        else:\n",
    "            print('Init with new values')\n",
    "            sess.run(tf.compat.v1.global_variables_initializer())\n",
    "\n",
    "        return (sess, saver)\n",
    "\n",
    "    def toSpare(self, texts):\n",
    "        \"\"\" Convert ground truth texts into sparse tensor for ctc_loss \"\"\"\n",
    "        indices = []\n",
    "        values = []\n",
    "        shape = [len(texts), 0]  # Last entry must be max(labelList[i])\n",
    "        # Go over all texts\n",
    "        for (batchElement, texts) in enumerate(texts):\n",
    "            # Convert to string of label (i.e. class-ids)\n",
    "            print(texts)\n",
    "            labelStr = []\n",
    "            for c in texts:\n",
    "                 print(c, '|', end='')\n",
    "                 labelStr.append(self.charList.index(c))\n",
    "            print(' ')\n",
    "            labelStr = [self.charList.index(c) for c in texts]\n",
    "            # Sparse tensor must have size of max. label-string\n",
    "            if len(labelStr) > shape[1]:\n",
    "                shape[1] = len(labelStr)\n",
    "            # Put each label into sparse tensor\n",
    "            for (i, label) in enumerate(labelStr):\n",
    "                indices.append([batchElement, i])\n",
    "                values.append(label)\n",
    "\n",
    "        return (indices, values, shape)\n",
    "\n",
    "    def decoderOutputToText(self, ctcOutput):\n",
    "        \"\"\" Extract texts from output of CTC decoder \"\"\"\n",
    "        # Contains string of labels for each batch element\n",
    "        encodedLabelStrs = [[] for i in range(Model.batchSize)]\n",
    "        # Word beam search: label strings terminated by blank\n",
    "        if self.decoderType == DecoderType.WordBeamSearch:\n",
    "            blank = len(self.charList)\n",
    "            for b in range(Model.batchSize):\n",
    "                for label in ctcOutput[b]:\n",
    "                    if label == blank:\n",
    "                        break\n",
    "                    encodedLabelStrs[b].append(label)\n",
    "        # TF decoders: label strings are contained in sparse tensor\n",
    "        else:\n",
    "            # Ctc returns tuple, first element is SparseTensor\n",
    "            decoded = ctcOutput[0][0]\n",
    "            # Go over all indices and save mapping: batch -> values\n",
    "            idxDict = {b : [] for b in range(Model.batchSize)}\n",
    "            for (idx, idx2d) in enumerate(decoded.indices):\n",
    "                label = decoded.values[idx]\n",
    "                batchElement = idx2d[0]  # index according to [b,t]\n",
    "                encodedLabelStrs[batchElement].append(label)\n",
    "        # Map labels to chars for all batch elements\n",
    "        return [str().join([self.charList[c] for c in labelStr]) for labelStr in encodedLabelStrs]\n",
    "\n",
    "    def trainBatch(self, batch, batchNum):\n",
    "        \"\"\" Feed a batch into the NN to train it \"\"\"\n",
    "        sparse = self.toSpare(batch.gtTexts)\n",
    "        rate = 0.001 # if you use the pretrained model to continue train\n",
    "        #rate = 0.01 if self.batchesTrained < 10 else (\n",
    "        #    0.001 if self.batchesTrained < 2750 else 0.001) # variable learning_rate is used from trained from scratch\n",
    "        evalList = [self.merge, self.optimizer, self.loss]\n",
    "        feedDict = {self.inputImgs: batch.imgs, self.gtTexts: sparse, self.seqLen: [Model.maxTextLen] * Model.batchSize, self.learningRate: rate}\n",
    "        (loss_summary, _, lossVal) = self.sess.run(evalList, feedDict)\n",
    "        # Tensorboard: Add loss_summary to writer\n",
    "        self.writer.add_summary(loss_summary, batchNum)\n",
    "        self.batchesTrained += 1\n",
    "        return lossVal\n",
    "\n",
    "    def return_rnn_out(self, batch, write_on_csv=False):\n",
    "        \"\"\"Only return rnn_out prediction value without decoded\"\"\"\n",
    "        numBatchElements = len(batch.imgs)\n",
    "        decoded, rnnOutput = self.sess.run([self.decoder, self.ctcIn3dTBC],\n",
    "                                {self.inputImgs: batch.imgs, self.seqLen: [Model.maxTextLen] * numBatchElements})\n",
    "\n",
    "        decoded = rnnOutput\n",
    "        print(decoded.shape)\n",
    "\n",
    "        if write_on_csv:\n",
    "            s = rnnOutput.shape\n",
    "            b = 0\n",
    "            csv = ''\n",
    "            for t in range(s[0]):\n",
    "                for c in range(s[2]):\n",
    "                    csv += str(rnnOutput[t, b, c]) + ';'\n",
    "                csv += '\\n'\n",
    "            open('mat_0.csv', 'w').write(csv)\n",
    "\n",
    "        return decoded[:,0,:].reshape(100,80)\n",
    "\n",
    "    def inferBatch(self, batch):\n",
    "        \"\"\" Feed a batch into the NN to recognize texts \"\"\"\n",
    "        numBatchElements = len(batch.imgs)\n",
    "        feedDict = {self.inputImgs: batch.imgs, self.seqLen: [Model.maxTextLen] * numBatchElements}\n",
    "        evalRes = self.sess.run([self.decoder, self.ctcIn3dTBC], feedDict)\n",
    "        decoded = evalRes[0]\n",
    "        # # Dump RNN output to .csv file\n",
    "        # decoded, rnnOutput = self.sess.run([self.decoder, self.rnnOutput], {\n",
    "        #                                    self.inputImgs: batch.imgs, self.seqLen: [Model.maxTextLen] * Model.batchSize})\n",
    "        # s = rnnOutput.shape\n",
    "        # b = 0\n",
    "        # csv = ''\n",
    "        # for t in range(s[0]):\n",
    "        #     for c in range(s[2]):\n",
    "        #         csv += str(rnnOutput[t, b, c]) + ';'\n",
    "        #     csv += '\\n'\n",
    "        # open('mat_0.csv', 'w').write(csv)\n",
    "\n",
    "        texts = self.decoderOutputToText(decoded)\n",
    "        return texts\n",
    "\n",
    "    def save(self):\n",
    "        \"\"\" Save model to file \"\"\"\n",
    "        self.snapID += 1\n",
    "        self.saver.save(self.sess, '../model/snapshot',\n",
    "                        global_step=self.snapID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
